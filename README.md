rancang sebagai solusi end-to-end yang komprehensif, mulai dari pemuatan data mentah hingga penyimpanan model terbaik yang siap digunakan. Tujuan utama dari kode ini adalah menyediakan kerangka kerja yang kuat dan otomatis untuk membandingkan performa algoritma Logistic Regression dan Random Forest, sembari menangani tantangan umum dalam data seperti nilai yang hilang (missing values) dan ketidakseimbangan kelas (class imbalance).

Sebelum menjalankan skrip ini, pastikan lingkungan Python Anda telah dilengkapi dengan pustaka-pustaka esensial untuk data science. Kode ini sangat bergantung pada pustaka pandas dan numpy untuk manajemen data tabular, scikit-learn untuk seluruh rangkaian preprocessing dan pemodelan, imbalanced-learn untuk teknik oversampling (SMOTE), matplotlib untuk visualisasi grafis, serta joblib untuk menyimpan objek model final. Pastikan seluruh dependensi tersebut telah terinstal agar tidak terjadi kesalahan saat eksekusi program.

Langkah awal penggunaan skrip ini adalah melakukan konfigurasi pada bagian User Config di dalam kode. Anda perlu menyesuaikan variabel PATH_DATA dengan lokasi file CSV dataset Anda dan variabel TARGET_COL dengan nama kolom yang menjadi target prediksi. Salah satu fitur keamanan yang disematkan dalam skrip ini adalah kemampuannya untuk mendeteksi ketersediaan file; jika file CSV yang Anda tentukan tidak ditemukan, sistem secara otomatis akan membangkitkan dataset sintetis (dummy) agar Anda tetap dapat menjalankan dan menguji alur kode tanpa error.

Setelah data dimuat, skrip akan membagi dataset menjadi data latih (training) dan data uji (testing) dengan proporsi yang menjaga distribusi kelas target tetap seimbang (stratified split). Proses preprocessing dilakukan menggunakan objek ColumnTransformer yang cerdas, yang secara otomatis memisahkan perlakuan untuk kolom numerik dan kategorikal. Kolom numerik akan mengalami pengisian nilai kosong menggunakan median dan disusul dengan standarisasi skala, sedangkan kolom kategorikal akan diisi dengan nilai modus (paling sering muncul) dan dikonversi menjadi angka menggunakan metode One-Hot Encoding.

Untuk menangani masalah ketidakseimbangan data yang sering menurunkan performa model pada kelas minoritas, skrip ini mengintegrasikan teknik SMOTE (Synthetic Minority Over-sampling Technique) di dalam pipeline. Penting untuk dicatat bahwa SMOTE hanya diterapkan pada proses validasi silang (cross-validation) dan data latih, sehingga data uji tetap murni dan tidak bocor (leakage). Selain itu, terdapat juga tahapan seleksi fitur otomatis menggunakan metode statistik ANOVA untuk menyaring fitur-fitur yang paling relevan sebelum data masuk ke algoritma pemodelan.

Pada tahap pemodelan inti, skrip melakukan pencarian hyperparameter (tuning) secara otomatis untuk dua algoritma, yaitu Logistic Regression dan Random Forest. Menggunakan metode RandomizedSearchCV dan GridSearchCV, sistem akan mencari kombinasi parameter terbaik dan jumlah fitur optimal yang menghasilkan skor validasi tertinggi. Setelah model terbaik terpilih, skrip akan melakukan evaluasi akhir pada data uji yang belum pernah dilihat sebelumnya. Hasil evaluasi berupa metrik Akurasi, Presisi, Recall, F1-Score, dan ROC-AUC akan ditampilkan di layar terminal untuk memberikan gambaran performa yang objektif.

Sebagai langkah penutup, skrip ini memiliki mekanisme pasca-pemrosesan yang bernilai tambah. Jika memungkinkan, skrip akan mencoba mengkalibrasi probabilitas model agar lebih akurat dan melakukan penyesuaian threshold keputusan untuk mendapatkan keseimbangan terbaik antara presisi dan recall. Akhirnya, model dengan performa terbaik akan disimpan secara otomatis ke dalam file bernama best_model.joblib untuk penggunaan di masa depan, dan sebuah grafik confusion matrix akan disimpan sebagai file gambar sebagai referensi visual hasil prediksi model.